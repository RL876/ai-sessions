{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47de5608-3c4e-4991-8a21-bef6c5677534",
   "metadata": {},
   "source": [
    "## CNN - Convolution Neural Network\n",
    "\n",
    "Learn the features from mesh data.\n",
    "\n",
    "![](https://miro.medium.com/v2/resize:fit:720/format:webp/1*RIBWK55dcDJa-zI_dFPDnw.png)\n",
    "\n",
    "![](https://saturncloud.io/images/blog/a-cnn-sequence-to-classify-handwritten-digits.webp)\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/9/90/CNN-filter-animation-1.gif?20230201202141)\n",
    "\n",
    "![](https://developers.google.com/static/machine-learning/practica/image-classification/images/maxpool_animation.gif?hl=zh-tw)\n",
    "\n",
    "![](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89419cb6-a807-4640-88b5-123dd8c1a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.loadtxt(\"sample_data/mnist_train_small.csv\", delimiter=\",\", dtype=int)\n",
    "X = arr[1:, 1:]\n",
    "Y = arr[1:, 0]\n",
    "print(f\"X: {len(X)}\\n\", X, \"\\n\", X[0])\n",
    "print(f\"Y: {len(Y)}\\n\", Y, \"\\n\", Y[0])\n",
    "from PIL import Image\n",
    "img = X[0]\n",
    "print(Y[0])\n",
    "Image.fromarray(img.reshape(28, 28).astype(np.uint8)).resize((140, 140)).show()\n",
    "def oneHot(y):\n",
    "    labels = np.unique(y)\n",
    "    labels.sort()\n",
    "    label_dict = dict()\n",
    "    for value in labels:\n",
    "        key = np.where(labels == value)[0][0]\n",
    "        label_dict[key] = str(value)\n",
    "        y = np.where(y == value, key, y)\n",
    "    y = y.astype(int)\n",
    "    # y = np.eye(len(np.unique(y)))[y].astype(int)\n",
    "    return y, label_dict\n",
    "\n",
    "Y, label_dict = oneHot(Y)\n",
    "X_train, X_test = X[:18000, :], X[18000:, :]\n",
    "Y_train, Y_test = Y[:18000], Y[18000:]\n",
    "print(Y_train)\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec180111-e69e-4682-b4de-e52ed6bdb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "X_train_tensor = torch.from_numpy(X_train.astype(\"float32\") / 255)\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(\"float32\") / 255)\n",
    "Y_train_tensor = torch.from_numpy(Y_train.astype(\"float32\")).type(torch.LongTensor)\n",
    "Y_test_tensor = torch.from_numpy(Y_test.astype(\"float32\")).type(torch.LongTensor)\n",
    "print(X_train_tensor)\n",
    "print(Y_train_tensor)\n",
    "# pytorch train and test TensorDataset\n",
    "train = torch.utils.data.TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "test = torch.utils.data.TensorDataset(X_test_tensor, Y_test_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcd74d-6d6d-4107-8980-c1fc72729313",
   "metadata": {},
   "source": [
    "![](https://saturncloud.io/images/blog/a-cnn-sequence-to-classify-handwritten-digits.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e97942-58f8-4ef8-93e5-48f6ede55070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 1e-3\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "# pytorch DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# define CNN Model\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolution 1 , input_shape=(1,28,28)\n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0) #output_shape=(16,24,24)\n",
    "        self.relu1 = torch.nn.ReLU() # activation\n",
    "        # Max pool 1\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2) #output_shape=(16,12,12)\n",
    "        # Convolution 2\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=0) #output_shape=(32,8,8)\n",
    "        self.relu2 = torch.nn.ReLU() # activation\n",
    "        # Max pool 2\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2) #output_shape=(32,4,4)\n",
    "        # Fully connected 1 ,#input_shape=(32*4*4)\n",
    "        self.fc1 = torch.nn.Linear(32 * 4 * 4, 10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        # Convolution 2 \n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "\n",
    "# training\n",
    "model = CNN()\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)   # optimize all cnn parameters\n",
    "loss_func = torch.nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "input_shape = (-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1d8f6-1cc1-4583-a1a7-d1291bbf0707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, loss_func, optimizer, input_shape, num_epochs, train_loader, test_loader):\n",
    "    # Traning the Model\n",
    "    #history-like list for store loss & acc value\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    validation_loss = []\n",
    "    validation_accuracy = []\n",
    "    for epoch in range(num_epochs):\n",
    "        #training model & store loss & acc / epoch\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            # 1.Define variables\n",
    "            train = torch.autograd.Variable(images.view(input_shape))\n",
    "            labels = torch.autograd.Variable(labels)\n",
    "            # 2.Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            # 3.Forward propagation\n",
    "            outputs = model(train)\n",
    "            # 4.Calculate softmax and cross entropy loss\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            # 5.Calculate gradients\n",
    "            train_loss.backward()\n",
    "            # 6.Update parameters\n",
    "            optimizer.step()\n",
    "            # 7.Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            # 8.Total number of labels\n",
    "            total_train += len(labels)\n",
    "            # 9.Total correct predictions\n",
    "            correct_train += (predicted == labels).float().sum()\n",
    "        #10.store val_acc / epoch\n",
    "        train_accuracy = 100 * correct_train / float(total_train)\n",
    "        training_accuracy.append(train_accuracy)\n",
    "        # 11.store loss / epoch\n",
    "        training_loss.append(train_loss.data)\n",
    "\n",
    "        #evaluate model & store loss & acc / epoch\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        for images, labels in test_loader:\n",
    "            # 1.Define variables\n",
    "            test = torch.autograd.Variable(images.view(input_shape))\n",
    "            # 2.Forward propagation\n",
    "            outputs = model(test)\n",
    "            # 3.Calculate softmax and cross entropy loss\n",
    "            val_loss = loss_func(outputs, labels)\n",
    "            # 4.Get predictions from the maximum value\n",
    "            predicted = torch.max(outputs.data, 1)[1]\n",
    "            # 5.Total number of labels\n",
    "            total_test += len(labels)\n",
    "            # 6.Total correct predictions\n",
    "            correct_test += (predicted == labels).float().sum()\n",
    "        #6.store val_acc / epoch\n",
    "        val_accuracy = 100 * correct_test / float(total_test)\n",
    "        validation_accuracy.append(val_accuracy)\n",
    "        # 11.store val_loss / epoch\n",
    "        validation_loss.append(val_loss.data)\n",
    "        print(\"Epoch {: 5d}/{}\\t- loss: {:.4f} - acc: {:.4f} - val_loss: {:.4f} - val_acc: {:.4f}\".format(epoch+1, num_epochs, train_loss.data, train_accuracy, val_loss.data, val_accuracy))\n",
    "    return training_loss, training_accuracy, validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e16ae9-13b1-41b4-ac6f-03a45767325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss, training_accuracy, validation_loss, validation_accuracy = fit_model(model, loss_func, optimizer, input_shape, epochs, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ea35b-e5a6-4e31-a824-83206729bb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(num_epochs), training_loss, 'b-', label='Training_loss')\n",
    "plt.plot(range(num_epochs), validation_loss, 'g-', label='validation_loss')\n",
    "plt.title('Training & Validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(range(num_epochs), training_accuracy, 'b-', label='Training_accuracy')\n",
    "plt.plot(range(num_epochs), validation_accuracy, 'g-', label='Validation_accuracy')\n",
    "plt.title('Training & Validation accuracy')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ed0e0-148b-4e65-b807-91df94a3c415",
   "metadata": {},
   "source": [
    "## Reference\n",
    "[PyTorch - CNN](https://hackmd.io/@lido2370/SJMPbNnKN?type=view)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
